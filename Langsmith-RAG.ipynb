{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using LangChain with Ollama in Python\n",
    "\n",
    "Let's imagine we are studying The Youth by Isaax Assimov. We might have a question about Slim and Red. If you ask llama3 for that info, you may get model hallucinations. \n",
    "\n",
    "This sounds like a typical censored response, but even llama3 gives a mediocre answer:\n",
    "\n",
    "> In Stephen Crane's novel \"The Youth\", Slim and Red are two main characters who have a significant interaction. Here's a brief summary:\n",
    "\n",
    "So let's figure out how we can use **LangChain** with Ollama to ask our question to the actual document, [The Youth](https://www.gutenberg.org/cache/epub/31547/pg31547-images.html) by Isaac Assimov, using Python.\n",
    "\n",
    "Let's start by asking a simple question that we can get an answer to from the **Llama2** model using **Ollama**. First, we need to install the **LangChain** package:\n",
    "\n",
    "`pip install langchain_community`\n",
    "\n",
    "Then we can create a model and ask the question:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " I apologize, but there is no work titled \"The Youth\" by Isaac Asimov that features a character named Slim or Red. Isaac Asimov was a prolific science fiction author, but I am not familiar with a work by him that includes these characters.\n",
      "\n",
      "Isaac Asimov wrote many books and short stories during his career, including \"The Foundation Series,\" \"The Galactic Empire Series,\" and \"The Robot Series,\" among others. However, I do not recall encountering Slim or Red as characters in any of his works.\n",
      "\n",
      "If you have any more information about the context of these characters, such as the specific work they appear in or any other details you may know, I would be happy to try and help you further.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "\n",
    "question = \"Can you summarize the interaction between Slim and Red in the Youth by Isaac Assimov?\"\n",
    "ollama = Ollama(\n",
    "    base_url='http://localhost:11434',\n",
    "    model=\"llama2\"\n",
    ")\n",
    "print(ollama.invoke(question))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wrong answerr. Hallucinating.\n",
    "Now let's load a document to ask questions against. I'll load up the Youth by Isaac Assimov, which you can find at Project Gutenberg. We will need **WebBaseLoader** which is part of **LangChain** and loads text from any webpage. On my machine, I also needed to install **bs4** to get that to work, so run `pip install bs4`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import WebBaseLoader\n",
    "loader = WebBaseLoader(\"https://www.gutenberg.org/cache/epub/31547/pg31547-images.html\")\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Llama-3 context size is 8000 tokens, which means the full document won't fit into the context for the model. So we need to split it up into smaller pieces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter=RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
    "all_splits = text_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's split up, but we have to find the relevant splits and then submit those to the model. We can do this by creating embeddings and storing them in a vector database. We can use Ollama directly to instantiate an embedding model. We will use ChromaDB in this example for a vector database. \n",
    "\n",
    "`pip install chromadb` // If you like to use a local installation of Chroma DB\n",
    "\n",
    "We also need to pull embedding model: `ollama pull nomic-embed-text`\n",
    "\n",
    "You can read more about Ollama supported embedding models [here](https://ollama.com/blog/embedding-models).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import OllamaEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "import chromadb\n",
    "\n",
    "# clear existing collections\n",
    "try:\n",
    "    chromadb.Client().delete_collection(\"langchain\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# create vector embeddings\n",
    "oembed = OllamaEmbeddings(base_url=\"http://localhost:11434\", model=\"nomic-embed-text\")\n",
    "\n",
    "# load splits to vector db\n",
    "vectorstore = Chroma.from_documents(documents=all_splits, embedding=oembed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's ask a question from the document. **Who was Neleus, and who is in his family?** Neleus is a character in the Odyssey, and the answer can be found in our text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = vectorstore.similarity_search(question)\n",
    "len(docs)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will output the number of matches for chunks of data similar to the search.\n",
    "\n",
    "The next thing is to send the question and the relevant parts of the docs to the model to see if we can get a good answer. But we are stitching two parts of the process together, and that is called a chain. This means we need to define a chain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to the provided context, here is a summary of the interaction between Slim and Red:\n",
      "\n",
      "Slim comes into the room unexpectedly and starts talking about having something that can get them into the circus. He proposes starting their own circus and becoming the biggest circus-fellows in the world. Red initially agrees to go along with the plan, but then takes it back after realizing that their parents might not approve of their idea. Slim seems disappointed by this turn of events, as he had been excited about the prospect of having a space-ship scout-ship.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "qachain=RetrievalQA.from_chain_type(ollama, retriever=vectorstore.as_retriever())\n",
    "res = qachain.invoke({\"query\": question})\n",
    "print(res['result'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracing using LangSmith"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load API key from secrets.json\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "\n",
    "\n",
    "def get_secrets():\n",
    "    with open('secrets.json') as secrets_file:\n",
    "        secrets = json.load(secrets_file)\n",
    "\n",
    "    return secrets\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    secrets = get_secrets()\n",
    "    os.environ[\"LANGCHAIN_API_KEY\"]  = secrets.get(\"LANGCHAIN_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import Client\n",
    "\n",
    "client = Client()\n",
    "\n",
    "# Define dataset: these are your test cases\n",
    "dataset_name = \"The Youth QA Dataset\"\n",
    "dataset = client.create_dataset(dataset_name)\n",
    "client.create_examples(\n",
    "    inputs=[\n",
    "        {\"question\": \"What is the significance of the title 'Youth'?\"},\n",
    "        {\"question\": \"Describe the relationship between Red and Slim in the story.\"},\n",
    "        {\"question\": \"How does Asimov use the theme of first contact in 'Youth'?\"},\n",
    "        {\"question\": \"What is the twist at the end of the story 'Youth'?\"},\n",
    "        {\"question\": \"What message does Asimov convey about the differences between children and adults?\"},\n",
    "    ],\n",
    "    outputs=[\n",
    "        {\"answer\": \"The title 'Youth' reflects the story's focus on the perspectives and actions of the young characters, Red and Slim. Their innocence and adventurous spirit contrast sharply with the adult world of negotiations and hidden agendas. The title also highlights the theme of perception and misunderstanding, as the boys' innocent misinterpretation of the situation leads to the story's twist.\"},\n",
    "        {\"answer\": \"Red and Slim share a close friendship based on their mutual curiosity and love for adventure. They are typical boys, eager to explore and discover new things. Their relationship is marked by innocence and a sense of wonder, which contrasts with the more serious and cautious interactions of the adults in the story.\"},\n",
    "        {\"answer\": \"Asimov uses the theme of first contact to explore the potential for both cooperation and misunderstanding between different species. The adults are engaged in serious negotiations, unaware that the animals the boys found are actually alien beings. This twist highlights how assumptions can lead to misunderstandings and how the innocence of youth can reveal truths that adults might overlook.\"},\n",
    "        {\"answer\": \"The twist at the end of 'Youth' is that the two animals that Red and Slim have found are actually the offspring of an alien species. This revelation turns the story on its head, as the adults' negotiations and the boys' innocent play are shown to be interconnected in a way that neither group understood.\"},\n",
    "        {\"answer\": \"Asimov conveys that children and adults perceive the world very differently. Children see the world with innocence and curiosity, often leading them to discover truths that adults might miss due to their preconceived notions and serious concerns. The story suggests that a balance of both perspectives can be valuable, and that sometimes, the simplicity of a child's view can uncover profound truths.\"},\n",
    "    ],\n",
    "    dataset_id=dataset.id,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create RAG System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import WebBaseLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import OllamaEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "loader = WebBaseLoader(\"https://www.gutenberg.org/cache/epub/31547/pg31547-images.html\")\n",
    "data = loader.load()\n",
    "text_splitter=RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
    "all_splits = text_splitter.split_documents(data)\n",
    "# create vector embeddings\n",
    "oembed = OllamaEmbeddings(base_url=\"http://localhost:11434\", model=\"nomic-embed-text\")\n",
    "\n",
    "# load splits to vector db\n",
    "vectorstore = Chroma.from_documents(documents=all_splits, embedding=oembed)\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful knowledgeable assistant, trained to answer\"\n",
    "            \" questions about the Youth by Isaac Assimov.\"\n",
    "            \"'Youth' is set in a future where humanity has achieved interstellar travel and encounters alien civilizations.\"\n",
    "            \"\\nThe current time is {time}.\\n\\nRelevant documents will be retrieved in the following messages.\",\n",
    "        ),\n",
    "        (\"system\", \"{context}\"),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ").partial(time=str(datetime.now()))\n",
    "\n",
    "model = Ollama(\n",
    "    base_url='http://localhost:11434',\n",
    "    model=\"llama2\"\n",
    ")\n",
    "response_generator = prompt | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an Evaluator LLM\n",
    "Here we will use Llama3 to evaulate the reponses of Llama2 on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model = Ollama(\n",
    "    base_url='http://localhost:11434',\n",
    "    model=\"llama2\"\n",
    ")\n",
    "# qa_evaluator = LangChainStringEvaluator(\"qa\", config={\"llm\": eval_llm, \"prompt\": PROMPT})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finally, assemble the full chain!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The full chain looks like the following\n",
    "from operator import itemgetter\n",
    "\n",
    "chain = (\n",
    "    # The runnable map here routes the original inputs to a context and a question dictionary to pass to the response generator\n",
    "    {\n",
    "        \"context\": itemgetter(\"question\")\n",
    "        | retriever\n",
    "        | (lambda docs: \"\\n\".join([doc.page_content for doc in docs])),\n",
    "        \"question\": itemgetter(\"question\"),\n",
    "    }\n",
    "    | response_generator\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.evaluation import load_evaluator\n",
    "\n",
    "# A string to prefix the experiment name with.\n",
    "# If not provided, a random string will be generated.\n",
    "experiment_prefix = \"The Youth QA Dataset\"\n",
    "\n",
    "# List of evaluators to score the outputs of target task\n",
    "evaluators = [\n",
    "    load_evaluator(\"labeled_criteria\", llm=eval_model, labeled_criteria=\"qa\"),\n",
    "    load_evaluator(\"labeled_criteria\", llm=eval_model, labeled_criteria=\"cot_qa\"),\n",
    "    load_evaluator(\"labeled_criteria\", llm=eval_model, criteria=\"coherence\"),\n",
    "    load_evaluator(\"labeled_criteria\", llm=eval_model, criteria=\"harmfulness\"),\n",
    "    load_evaluator(\"labeled_criteria\", llm=eval_model, criteria=\"depth\")\n",
    "]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'The Youth QA Dataset-b9bc66df' at:\n",
      "https://smith.langchain.com/o/103e639e-1fea-5efb-81b6-6b537ff4132d/datasets/fc9382e7-72de-416e-a423-9e372b0ef23b/compare?selectedSessions=d4dae24c-e48e-4cae-bba9-b5aabc1f4919\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b498cfea7b340ec9530fe281ad93820",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error running evaluator <DynamicRunEvaluator wrapper> on run 275fc137-b022-476f-b037-2db8ad37ff87: AttributeError(\"'LabeledCriteriaEvalChain' object has no attribute '__name__'\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/vedantjain/anaconda3/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1231, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/vedantjain/anaconda3/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/vedantjain/anaconda3/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 550, in wrapper\n",
      "    run_container = _setup_run(\n",
      "  File \"/Users/vedantjain/anaconda3/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 1028, in _setup_run\n",
      "    name_ = name or func.__name__\n",
      "AttributeError: 'LabeledCriteriaEvalChain' object has no attribute '__name__'\n",
      "Error running evaluator <DynamicRunEvaluator wrapper> on run 5ea3ee6c-1b43-4db1-8018-56283f448ddd: AttributeError(\"'LabeledCriteriaEvalChain' object has no attribute '__name__'\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/vedantjain/anaconda3/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1231, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/vedantjain/anaconda3/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/vedantjain/anaconda3/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 550, in wrapper\n",
      "    run_container = _setup_run(\n",
      "  File \"/Users/vedantjain/anaconda3/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 1028, in _setup_run\n",
      "    name_ = name or func.__name__\n",
      "AttributeError: 'LabeledCriteriaEvalChain' object has no attribute '__name__'\n",
      "Error running evaluator <DynamicRunEvaluator wrapper> on run 07aecc02-2571-4625-86d8-75c4c84ddc80: AttributeError(\"'LabeledCriteriaEvalChain' object has no attribute '__name__'\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/vedantjain/anaconda3/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1231, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/vedantjain/anaconda3/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/vedantjain/anaconda3/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 550, in wrapper\n",
      "    run_container = _setup_run(\n",
      "  File \"/Users/vedantjain/anaconda3/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 1028, in _setup_run\n",
      "    name_ = name or func.__name__\n",
      "AttributeError: 'LabeledCriteriaEvalChain' object has no attribute '__name__'\n",
      "Error running evaluator <DynamicRunEvaluator wrapper> on run 8ac2b06d-7a3d-4145-ac12-274db0d164fe: AttributeError(\"'LabeledCriteriaEvalChain' object has no attribute '__name__'\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/vedantjain/anaconda3/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1231, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/vedantjain/anaconda3/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/vedantjain/anaconda3/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 550, in wrapper\n",
      "    run_container = _setup_run(\n",
      "  File \"/Users/vedantjain/anaconda3/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 1028, in _setup_run\n",
      "    name_ = name or func.__name__\n",
      "AttributeError: 'LabeledCriteriaEvalChain' object has no attribute '__name__'\n",
      "Error running evaluator <DynamicRunEvaluator wrapper> on run 9fbea1ec-a640-4e89-8256-cb4781acb092: AttributeError(\"'LabeledCriteriaEvalChain' object has no attribute '__name__'\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/vedantjain/anaconda3/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1231, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/vedantjain/anaconda3/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/vedantjain/anaconda3/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 550, in wrapper\n",
      "    run_container = _setup_run(\n",
      "  File \"/Users/vedantjain/anaconda3/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 1028, in _setup_run\n",
      "    name_ = name or func.__name__\n",
      "AttributeError: 'LabeledCriteriaEvalChain' object has no attribute '__name__'\n",
      "Error running evaluator <DynamicRunEvaluator wrapper> on run 275fc137-b022-476f-b037-2db8ad37ff87: AttributeError(\"'LabeledCriteriaEvalChain' object has no attribute '__name__'\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/vedantjain/anaconda3/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1231, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/vedantjain/anaconda3/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/vedantjain/anaconda3/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 550, in wrapper\n",
      "    run_container = _setup_run(\n",
      "  File \"/Users/vedantjain/anaconda3/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 1028, in _setup_run\n",
      "    name_ = name or func.__name__\n",
      "AttributeError: 'LabeledCriteriaEvalChain' object has no attribute '__name__'\n",
      "Error running evaluator <DynamicRunEvaluator wrapper> on run 5ea3ee6c-1b43-4db1-8018-56283f448ddd: AttributeError(\"'LabeledCriteriaEvalChain' object has no attribute '__name__'\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/vedantjain/anaconda3/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1231, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/vedantjain/anaconda3/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/vedantjain/anaconda3/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 550, in wrapper\n",
      "    run_container = _setup_run(\n",
      "  File \"/Users/vedantjain/anaconda3/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 1028, in _setup_run\n",
      "    name_ = name or func.__name__\n",
      "AttributeError: 'LabeledCriteriaEvalChain' object has no attribute '__name__'\n",
      "Error running evaluator <DynamicRunEvaluator wrapper> on run 07aecc02-2571-4625-86d8-75c4c84ddc80: AttributeError(\"'LabeledCriteriaEvalChain' object has no attribute '__name__'\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/vedantjain/anaconda3/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1231, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/vedantjain/anaconda3/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/vedantjain/anaconda3/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 550, in wrapper\n",
      "    run_container = _setup_run(\n",
      "  File \"/Users/vedantjain/anaconda3/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 1028, in _setup_run\n",
      "    name_ = name or func.__name__\n",
      "AttributeError: 'LabeledCriteriaEvalChain' object has no attribute '__name__'\n",
      "Error running evaluator <DynamicRunEvaluator wrapper> on run 8ac2b06d-7a3d-4145-ac12-274db0d164fe: AttributeError(\"'LabeledCriteriaEvalChain' object has no attribute '__name__'\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/vedantjain/anaconda3/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1231, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/vedantjain/anaconda3/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/vedantjain/anaconda3/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 550, in wrapper\n",
      "    run_container = _setup_run(\n",
      "  File \"/Users/vedantjain/anaconda3/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 1028, in _setup_run\n",
      "    name_ = name or func.__name__\n",
      "AttributeError: 'LabeledCriteriaEvalChain' object has no attribute '__name__'\n",
      "Error running evaluator <DynamicRunEvaluator wrapper> on run 9fbea1ec-a640-4e89-8256-cb4781acb092: AttributeError(\"'LabeledCriteriaEvalChain' object has no attribute '__name__'\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/vedantjain/anaconda3/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1231, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/vedantjain/anaconda3/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/vedantjain/anaconda3/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 550, in wrapper\n",
      "    run_container = _setup_run(\n",
      "  File \"/Users/vedantjain/anaconda3/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 1028, in _setup_run\n",
      "    name_ = name or func.__name__\n",
      "AttributeError: 'LabeledCriteriaEvalChain' object has no attribute '__name__'\n",
      "Error running evaluator <DynamicRunEvaluator wrapper> on run 275fc137-b022-476f-b037-2db8ad37ff87: AttributeError(\"'LabeledCriteriaEvalChain' object has no attribute '__name__'\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/vedantjain/anaconda3/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1231, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/vedantjain/anaconda3/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/vedantjain/anaconda3/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 550, in wrapper\n",
      "    run_container = _setup_run(\n",
      "  File \"/Users/vedantjain/anaconda3/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 1028, in _setup_run\n",
      "    name_ = name or func.__name__\n",
      "AttributeError: 'LabeledCriteriaEvalChain' object has no attribute '__name__'\n",
      "Error running evaluator <DynamicRunEvaluator wrapper> on run 5ea3ee6c-1b43-4db1-8018-56283f448ddd: AttributeError(\"'LabeledCriteriaEvalChain' object has no attribute '__name__'\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/vedantjain/anaconda3/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1231, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/vedantjain/anaconda3/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/vedantjain/anaconda3/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 550, in wrapper\n",
      "    run_container = _setup_run(\n",
      "  File \"/Users/vedantjain/anaconda3/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 1028, in _setup_run\n",
      "    name_ = name or func.__name__\n",
      "AttributeError: 'LabeledCriteriaEvalChain' object has no attribute '__name__'\n",
      "Error running evaluator <DynamicRunEvaluator wrapper> on run 07aecc02-2571-4625-86d8-75c4c84ddc80: AttributeError(\"'LabeledCriteriaEvalChain' object has no attribute '__name__'\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/vedantjain/anaconda3/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1231, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/vedantjain/anaconda3/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/vedantjain/anaconda3/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 550, in wrapper\n",
      "    run_container = _setup_run(\n",
      "  File \"/Users/vedantjain/anaconda3/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 1028, in _setup_run\n",
      "    name_ = name or func.__name__\n",
      "AttributeError: 'LabeledCriteriaEvalChain' object has no attribute '__name__'\n",
      "Error running evaluator <DynamicRunEvaluator wrapper> on run 8ac2b06d-7a3d-4145-ac12-274db0d164fe: AttributeError(\"'LabeledCriteriaEvalChain' object has no attribute '__name__'\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/vedantjain/anaconda3/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1231, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/vedantjain/anaconda3/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/vedantjain/anaconda3/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 550, in wrapper\n",
      "    run_container = _setup_run(\n",
      "  File \"/Users/vedantjain/anaconda3/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 1028, in _setup_run\n",
      "    name_ = name or func.__name__\n",
      "AttributeError: 'LabeledCriteriaEvalChain' object has no attribute '__name__'\n",
      "Error running evaluator <DynamicRunEvaluator wrapper> on run 9fbea1ec-a640-4e89-8256-cb4781acb092: AttributeError(\"'LabeledCriteriaEvalChain' object has no attribute '__name__'\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/vedantjain/anaconda3/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1231, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/vedantjain/anaconda3/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/vedantjain/anaconda3/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 550, in wrapper\n",
      "    run_container = _setup_run(\n",
      "  File \"/Users/vedantjain/anaconda3/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 1028, in _setup_run\n",
      "    name_ = name or func.__name__\n",
      "AttributeError: 'LabeledCriteriaEvalChain' object has no attribute '__name__'\n",
      "Error running evaluator <DynamicRunEvaluator wrapper> on run 275fc137-b022-476f-b037-2db8ad37ff87: AttributeError(\"'LabeledCriteriaEvalChain' object has no attribute '__name__'\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/vedantjain/anaconda3/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1231, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/vedantjain/anaconda3/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/vedantjain/anaconda3/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 550, in wrapper\n",
      "    run_container = _setup_run(\n",
      "  File \"/Users/vedantjain/anaconda3/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 1028, in _setup_run\n",
      "    name_ = name or func.__name__\n",
      "AttributeError: 'LabeledCriteriaEvalChain' object has no attribute '__name__'\n",
      "Error running evaluator <DynamicRunEvaluator wrapper> on run 5ea3ee6c-1b43-4db1-8018-56283f448ddd: AttributeError(\"'LabeledCriteriaEvalChain' object has no attribute '__name__'\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/vedantjain/anaconda3/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1231, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/vedantjain/anaconda3/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/vedantjain/anaconda3/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 550, in wrapper\n",
      "    run_container = _setup_run(\n",
      "  File \"/Users/vedantjain/anaconda3/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 1028, in _setup_run\n",
      "    name_ = name or func.__name__\n",
      "AttributeError: 'LabeledCriteriaEvalChain' object has no attribute '__name__'\n",
      "Error running evaluator <DynamicRunEvaluator wrapper> on run 07aecc02-2571-4625-86d8-75c4c84ddc80: AttributeError(\"'LabeledCriteriaEvalChain' object has no attribute '__name__'\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/vedantjain/anaconda3/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1231, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/vedantjain/anaconda3/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/vedantjain/anaconda3/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 550, in wrapper\n",
      "    run_container = _setup_run(\n",
      "  File \"/Users/vedantjain/anaconda3/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 1028, in _setup_run\n",
      "    name_ = name or func.__name__\n",
      "AttributeError: 'LabeledCriteriaEvalChain' object has no attribute '__name__'\n",
      "Error running evaluator <DynamicRunEvaluator wrapper> on run 8ac2b06d-7a3d-4145-ac12-274db0d164fe: AttributeError(\"'LabeledCriteriaEvalChain' object has no attribute '__name__'\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/vedantjain/anaconda3/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1231, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/vedantjain/anaconda3/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/vedantjain/anaconda3/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 550, in wrapper\n",
      "    run_container = _setup_run(\n",
      "  File \"/Users/vedantjain/anaconda3/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 1028, in _setup_run\n",
      "    name_ = name or func.__name__\n",
      "AttributeError: 'LabeledCriteriaEvalChain' object has no attribute '__name__'\n",
      "Error running evaluator <DynamicRunEvaluator wrapper> on run 9fbea1ec-a640-4e89-8256-cb4781acb092: AttributeError(\"'LabeledCriteriaEvalChain' object has no attribute '__name__'\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/vedantjain/anaconda3/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1231, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/vedantjain/anaconda3/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/vedantjain/anaconda3/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 550, in wrapper\n",
      "    run_container = _setup_run(\n",
      "  File \"/Users/vedantjain/anaconda3/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 1028, in _setup_run\n",
      "    name_ = name or func.__name__\n",
      "AttributeError: 'LabeledCriteriaEvalChain' object has no attribute '__name__'\n",
      "Error running evaluator <DynamicRunEvaluator wrapper> on run 275fc137-b022-476f-b037-2db8ad37ff87: AttributeError(\"'LabeledCriteriaEvalChain' object has no attribute '__name__'\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/vedantjain/anaconda3/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1231, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/vedantjain/anaconda3/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/vedantjain/anaconda3/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 550, in wrapper\n",
      "    run_container = _setup_run(\n",
      "  File \"/Users/vedantjain/anaconda3/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 1028, in _setup_run\n",
      "    name_ = name or func.__name__\n",
      "AttributeError: 'LabeledCriteriaEvalChain' object has no attribute '__name__'\n",
      "Error running evaluator <DynamicRunEvaluator wrapper> on run 5ea3ee6c-1b43-4db1-8018-56283f448ddd: AttributeError(\"'LabeledCriteriaEvalChain' object has no attribute '__name__'\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/vedantjain/anaconda3/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1231, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/vedantjain/anaconda3/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/vedantjain/anaconda3/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 550, in wrapper\n",
      "    run_container = _setup_run(\n",
      "  File \"/Users/vedantjain/anaconda3/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 1028, in _setup_run\n",
      "    name_ = name or func.__name__\n",
      "AttributeError: 'LabeledCriteriaEvalChain' object has no attribute '__name__'\n",
      "Error running evaluator <DynamicRunEvaluator wrapper> on run 07aecc02-2571-4625-86d8-75c4c84ddc80: AttributeError(\"'LabeledCriteriaEvalChain' object has no attribute '__name__'\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/vedantjain/anaconda3/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1231, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/vedantjain/anaconda3/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/vedantjain/anaconda3/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 550, in wrapper\n",
      "    run_container = _setup_run(\n",
      "  File \"/Users/vedantjain/anaconda3/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 1028, in _setup_run\n",
      "    name_ = name or func.__name__\n",
      "AttributeError: 'LabeledCriteriaEvalChain' object has no attribute '__name__'\n",
      "Error running evaluator <DynamicRunEvaluator wrapper> on run 8ac2b06d-7a3d-4145-ac12-274db0d164fe: AttributeError(\"'LabeledCriteriaEvalChain' object has no attribute '__name__'\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/vedantjain/anaconda3/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1231, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/vedantjain/anaconda3/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/vedantjain/anaconda3/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 550, in wrapper\n",
      "    run_container = _setup_run(\n",
      "  File \"/Users/vedantjain/anaconda3/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 1028, in _setup_run\n",
      "    name_ = name or func.__name__\n",
      "AttributeError: 'LabeledCriteriaEvalChain' object has no attribute '__name__'\n",
      "Error running evaluator <DynamicRunEvaluator wrapper> on run 9fbea1ec-a640-4e89-8256-cb4781acb092: AttributeError(\"'LabeledCriteriaEvalChain' object has no attribute '__name__'\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/vedantjain/anaconda3/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1231, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/vedantjain/anaconda3/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/vedantjain/anaconda3/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 550, in wrapper\n",
      "    run_container = _setup_run(\n",
      "  File \"/Users/vedantjain/anaconda3/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 1028, in _setup_run\n",
      "    name_ = name or func.__name__\n",
      "AttributeError: 'LabeledCriteriaEvalChain' object has no attribute '__name__'\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the target task\n",
    "results = evaluate(\n",
    "  chain.invoke,\n",
    "  data=dataset_name,\n",
    "  evaluators=evaluators,\n",
    "  experiment_prefix=experiment_prefix,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.smith import RunEvalConfig\n",
    "\n",
    "eval_config = RunEvalConfig(\n",
    "    evaluators=[\"qa\", \"cot_qa\", \"context_qa\", \"labeled_criteria\"],\n",
    "    eval_llm=eval_model\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the evaluation. This makes predictions over the dataset and then uses the \"QA\" evaluator to check the correctness on each data point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for project 'upbeat-friend-9' at:\n",
      "https://smith.langchain.com/o/103e639e-1fea-5efb-81b6-6b537ff4132d/datasets/fc9382e7-72de-416e-a423-9e372b0ef23b/compare?selectedSessions=2260105e-d1fb-4d8e-b009-163b452b0da0\n",
      "\n",
      "View all tests for Dataset The Youth QA Dataset at:\n",
      "https://smith.langchain.com/o/103e639e-1fea-5efb-81b6-6b537ff4132d/datasets/fc9382e7-72de-416e-a423-9e372b0ef23b\n",
      "[------------------------------------------------->] 5/5"
     ]
    }
   ],
   "source": [
    "_ = await client.arun_on_dataset(\n",
    "    dataset_name=dataset_name,\n",
    "    llm_or_chain_factory=lambda: chain,\n",
    "    evaluation=eval_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
